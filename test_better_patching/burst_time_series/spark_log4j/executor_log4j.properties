# Default logging for project
log4j.logger.com.sap.altiscale.datapipeline.applicationsummary_slothours=${APPSUM_LOGLEVEL}, DRFA

# Define the root logger to the application property
log4j.rootLogger=WARN
log4j.rootCategory=WARN, DRFA

# Define some default values that can be overridden by system properties
spark.log.threshold=WARN
spark.root.logger=WARN, DRFA
spark.log.dir=${spark.yarn.app.container.log.dir}
spark.log.file=spark-executor.log

# Settings to quiet third party logs that are too verbose
log4j.logger.org.spark-project.jetty=WARN
log4j.logger.org.spark-project.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR

# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR

###############################
# Daily Rolling File Appender #
###############################
# Use the PidDailyerRollingFileAppend class instead if you want to use separate log files
# for different CLI session.
#
# log4j.appender.DRFA=org.apache.hadoop.spark.ql.log.PidDailyRollingFileAppender
log4j.appender.DRFA=org.apache.log4j.DailyRollingFileAppender
log4j.appender.DRFA.File=${spark.log.dir}/${spark.log.file}
# Rollver at midnight
log4j.appender.DRFA.DatePattern=.yyyy-MM-dd
# 30-day backup
#log4j.appender.DRFA.MaxBackupIndex=30
log4j.appender.DRFA.layout=org.apache.log4j.PatternLayout
# Pattern format: Date LogLevel LoggerName LogMessage
#log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %p %c: %m%n
# Debugging Pattern format
# log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %-5p %c{2} (%F:%M(%L)) - %m%n
# We want to print out the full classpath + pkg name for troubleshooting
log4j.appender.DRFA.layout.ConversionPattern=%d{ISO8601} %-5p %c (%F:%M(%L)) - %m%n

####################
# Console Appender #
####################
# Set everything to be logged to the console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.threshold=ALL
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{ISO8601} %-5p %c (%F:%M(%L)) - %m%n
log4j.appender.console.encoding=UTF-8

log4j.appender.spark=org.apache.log4j.ConsoleAppender
log4j.appender.spark.threshold=WARN
log4j.appender.spark.target=System.err
log4j.appender.spark.layout=org.apache.log4j.PatternLayout
log4j.appender.spark.layout.ConversionPattern=%d{ISO8601} %-5p %c (%F:%M(%L)) - %m%n
log4j.appender.spark.encoding=UTF-8

log4j.appender.sparkyarn=org.apache.log4j.ConsoleAppender
log4j.appender.sparkyarn.threshold=WARN
log4j.appender.sparkyarn.target=System.err
log4j.appender.sparkyarn.layout=org.apache.log4j.PatternLayout
log4j.appender.sparkyarn.layout.ConversionPattern=%d{ISO8601} %-5p %c (%F:%M(%L)) - %m%n
log4j.appender.sparkyarn.encoding=UTF-8

log4j.appender.sparkhivethrift=org.apache.log4j.ConsoleAppender
log4j.appender.sparkhivethrift.threshold=INFO
log4j.appender.sparkhivethrift.target=System.err
log4j.appender.sparkhivethrift.layout=org.apache.log4j.PatternLayout
log4j.appender.sparkhivethrift.layout.ConversionPattern=%d{ISO8601} %-5p %c (%F:%M(%L)) - %m%n
log4j.appender.sparkhivethrift.encoding=UTF-8

log4j.appender.hivecli=org.apache.log4j.ConsoleAppender
log4j.appender.hivecli.threshold=INFO
log4j.appender.hivecli.target=System.err
log4j.appender.hivecli.layout=org.apache.log4j.PatternLayout
log4j.appender.hivecli.layout.ConversionPattern=%d{ISO8601} %-5p %c (%F:%M(%L)) - %m%n
log4j.appender.hivecli.encoding=UTF-8

log4j.category.DataNucleus=ERROR,console
log4j.category.Datastore=ERROR,console
log4j.category.Datastore.Schema=ERROR,console
log4j.category.JPOX.Datastore=ERROR,console
log4j.category.JPOX.Plugin=ERROR,console
log4j.category.JPOX.MetaData=ERROR,console
log4j.category.JPOX.Query=ERROR,console
log4j.category.JPOX.General=ERROR,console
log4j.category.JPOX.Enhancer=ERROR,console

log4j.logger.org.apache.hadoop.hive.cli.OptionsProcessor=WARN, console

log4j.additivity.org.apache.spark.deploy=false
log4j.additivity.org.apache.spark.deploy.yarn=false
log4j.additivity.org.apache.spark.repl=false
log4j.additivity.org.apache.hadoop.util=false
log4j.additivity.org.apache.hadoop.hive.cli=false
log4j.additivity.org.apache.spark.sql.hive.thriftserver=false
log4j.logger.org.apache.spark.deploy=INFO, spark
log4j.logger.org.apache.spark.deploy.yarn=INFO, sparkyarn
log4j.logger.org.apache.spark.repl=INFO, console
log4j.logger.org.apache.hadoop.util=INFO, console
log4j.logger.org.apache.hadoop.hive.cli=INFO, hivecli
log4j.logger.org.apache.spark.sql.hive.thriftserver=INFO, sparkhivethrift
